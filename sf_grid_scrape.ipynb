{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: playwright in /Users/evieculloty/opt/anaconda3/lib/python3.8/site-packages (1.48.0)\n",
      "Requirement already satisfied: pandas in /Users/evieculloty/opt/anaconda3/lib/python3.8/site-packages (1.1.3)\n",
      "Requirement already satisfied: pytz in /Users/evieculloty/opt/anaconda3/lib/python3.8/site-packages (2020.1)\n",
      "Requirement already satisfied: greenlet==3.1.1 in /Users/evieculloty/opt/anaconda3/lib/python3.8/site-packages (from playwright) (3.1.1)\n",
      "Requirement already satisfied: pyee==12.0.0 in /Users/evieculloty/opt/anaconda3/lib/python3.8/site-packages (from playwright) (12.0.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/evieculloty/opt/anaconda3/lib/python3.8/site-packages (from pyee==12.0.0->playwright) (4.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/evieculloty/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/evieculloty/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/evieculloty/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install playwright pandas pytz\n",
    "!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pytz import timezone\n",
    "from playwright.async_api import async_playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ts_utc gpu_type  gpu_count duration  usd_per_gpu_hr\n",
      "0   2025-09-03T16:02:08     H100          8   1 hour            1.40\n",
      "1   2025-09-03T16:02:08     H100         16   1 hour            1.40\n",
      "2   2025-09-03T16:02:08     H100         32   1 hour            1.40\n",
      "3   2025-09-03T16:02:08     H100         64   1 hour            1.40\n",
      "4   2025-09-03T16:02:08     H100        128   1 hour            1.44\n",
      "5   2025-09-03T16:02:08     H100        256   1 hour            1.55\n",
      "6   2025-09-03T16:02:08     H100          8    1 day            1.40\n",
      "7   2025-09-03T16:02:08     H100         16    1 day            1.40\n",
      "8   2025-09-03T16:02:08     H100         32    1 day            1.40\n",
      "9   2025-09-03T16:02:08     H100         64    1 day            1.40\n",
      "10  2025-09-03T16:02:08     H100        128    1 day            1.40\n",
      "11  2025-09-03T16:02:08     H100        256    1 day            1.77\n",
      "12  2025-09-03T16:02:08     H100          8   1 week            1.40\n",
      "13  2025-09-03T16:02:08     H100         16   1 week            1.40\n",
      "14  2025-09-03T16:02:08     H100         32   1 week            1.40\n",
      "15  2025-09-03T16:02:08     H100         64   1 week            1.40\n",
      "16  2025-09-03T16:02:08     H100        128   1 week            1.40\n",
      "17  2025-09-03T16:02:08     H100        256   1 week             NaN\n",
      "18  2025-09-03T16:02:08     H100          8  1 month            1.40\n",
      "19  2025-09-03T16:02:08     H100         16  1 month            1.40\n",
      "20  2025-09-03T16:02:08     H100         32  1 month            1.40\n",
      "21  2025-09-03T16:02:08     H100         64  1 month            1.40\n",
      "22  2025-09-03T16:02:08     H100        128  1 month            1.40\n",
      "23  2025-09-03T16:02:08     H100        256  1 month             NaN\n",
      "24  2025-09-03T16:02:08     H200          8   1 hour            2.10\n",
      "25  2025-09-03T16:02:08     H200         16   1 hour            2.09\n",
      "26  2025-09-03T16:02:08     H200         32   1 hour            2.10\n",
      "27  2025-09-03T16:02:08     H200         64   1 hour            2.09\n",
      "28  2025-09-03T16:02:08     H200        128   1 hour             NaN\n",
      "29  2025-09-03T16:02:08     H200        256   1 hour             NaN\n",
      "30  2025-09-03T16:02:08     H200          8    1 day            2.10\n",
      "31  2025-09-03T16:02:08     H200         16    1 day            2.10\n",
      "32  2025-09-03T16:02:08     H200         32    1 day            2.10\n",
      "33  2025-09-03T16:02:08     H200         64    1 day            2.10\n",
      "34  2025-09-03T16:02:08     H200        128    1 day             NaN\n",
      "35  2025-09-03T16:02:08     H200        256    1 day             NaN\n",
      "36  2025-09-03T16:02:08     H200          8   1 week            2.10\n",
      "37  2025-09-03T16:02:08     H200         16   1 week            2.10\n",
      "38  2025-09-03T16:02:08     H200         32   1 week            2.10\n",
      "39  2025-09-03T16:02:08     H200         64   1 week            2.10\n",
      "40  2025-09-03T16:02:08     H200        128   1 week             NaN\n",
      "41  2025-09-03T16:02:08     H200        256   1 week             NaN\n",
      "42  2025-09-03T16:02:08     H200          8  1 month            2.10\n",
      "43  2025-09-03T16:02:08     H200         16  1 month            2.10\n",
      "44  2025-09-03T16:02:08     H200         32  1 month            2.10\n",
      "45  2025-09-03T16:02:08     H200         64  1 month            2.10\n",
      "46  2025-09-03T16:02:08     H200        128  1 month             NaN\n",
      "47  2025-09-03T16:02:08     H200        256  1 month             NaN\n",
      "Saved: sfcompute_grid/grid_20250903.csv\n",
      "History file updated: sfcompute_grid/grid_history.csv\n"
     ]
    }
   ],
   "source": [
    "# SF Compute price grid (keep your flow; fix \"1 week\" + all counts)\n",
    "import re, nest_asyncio, asyncio, datetime as dt, pandas as pd\n",
    "from pathlib import Path\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "GPU_TYPES = [\"H100\", \"H200\"]\n",
    "DURATIONS_EXPECTED = [\"1 hour\", \"1 day\", \"1 week\", \"1 month\"]\n",
    "\n",
    "# Strict $-anchored price AND a decimal fallback (used only when $ not in text)\n",
    "PRICE_RE = re.compile(r\"(?<=\\$)\\s*([0-9]+(?:\\.[0-9]{1,3})?)\")\n",
    "DECIMAL_FALLBACK_RE = re.compile(r\"([0-9]+(?:\\.[0-9]{1,3}))\")\n",
    "\n",
    "\n",
    "async def _select_explore_prices_tab(page):\n",
    "    try:\n",
    "        await page.get_by_role(\"tab\", name=re.compile(r\"Explore Prices\", re.I)).click(timeout=1500)\n",
    "    except:\n",
    "        try:\n",
    "            await page.get_by_text(re.compile(r\"Explore Prices\", re.I)).first.click(timeout=1500)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "async def _select_gpu(page, gpu_label: str):\n",
    "    \"\"\"Robustly select GPU type (H100/H200).\"\"\"\n",
    "    # 1) Native <select>\n",
    "    try:\n",
    "        sel = page.get_by_role(\"combobox\").first\n",
    "        if await sel.count() > 0:\n",
    "            await sel.select_option(label=gpu_label)\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    # 2) Custom dropdown\n",
    "    try:\n",
    "        dd = page.get_by_role(\"button\", name=re.compile(r\"H100|H200\", re.I)).first\n",
    "        if await dd.count() == 0:\n",
    "            dd = page.locator(\"div,button,[role='button']\").filter(has_text=re.compile(r\"H100|H200\")).first\n",
    "        await dd.click(timeout=1500)\n",
    "        await page.get_by_text(re.compile(rf\"^{gpu_label}$\", re.I)).first.click(timeout=1500)\n",
    "        return True\n",
    "    except:\n",
    "        pass\n",
    "    # 3) Button toggle\n",
    "    try:\n",
    "        await page.get_by_role(\"button\", name=re.compile(rf\"^{gpu_label}$\", re.I)).first.click(timeout=1500)\n",
    "        return True\n",
    "    except:\n",
    "        pass\n",
    "    # 4) Fallback\n",
    "    try:\n",
    "        await page.get_by_text(re.compile(rf\"^{gpu_label}$\", re.I)).first.click(timeout=1500)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "async def _wait_table_update(page, expected_gpu: str):\n",
    "    tbl = page.locator(\"table\").first\n",
    "    if await page.locator(\"table\").count() == 0:\n",
    "        tbl = page.locator(\"section, div\").filter(\n",
    "            has_text=re.compile(\"1 hour|1 day|1 week|1 month\", re.I)\n",
    "        ).first\n",
    "    try:\n",
    "        await tbl.wait_for(state=\"visible\", timeout=6000)\n",
    "    except:\n",
    "        pass\n",
    "    # settle after GPU switch so the row texts are fresh\n",
    "    await page.wait_for_timeout(400)\n",
    "    return tbl\n",
    "\n",
    "def _slice_one_row_text(full_text: str, dur: str) -> str:\n",
    "    \"\"\"Take only the text segment from this duration label up to the next duration label.\"\"\"\n",
    "    lo = full_text.lower()\n",
    "    start = lo.find(dur)\n",
    "    if start == -1:\n",
    "        return \"\"\n",
    "    next_pos = len(full_text)\n",
    "    for other in DURATIONS_EXPECTED:\n",
    "        if other == dur:\n",
    "            continue\n",
    "        p = lo.find(other, start + 1)\n",
    "        if p != -1:\n",
    "            next_pos = min(next_pos, p)\n",
    "    return full_text[start:next_pos]\n",
    "\n",
    "# ---------- NEW: DOM fallback for rows where '$' is CSS-injected (e.g., '1 week') ----------\n",
    "async def _extract_row_prices_via_dom(table_locator, dur: str, ncols: int):\n",
    "    \"\"\"\n",
    "    Find the visual row that contains `dur` and pull texts/attributes from its cells.\n",
    "    Returns a list of length ncols with floats or None.\n",
    "    \"\"\"\n",
    "    # locate the label element first\n",
    "    label_loc = table_locator.get_by_text(re.compile(rf\"\\b{re.escape(dur)}\\b\", re.I)).first\n",
    "    if await label_loc.count() == 0:\n",
    "        return None\n",
    "\n",
    "    # Grab candidate cell texts/attributes from the same row container\n",
    "    cell_texts = await label_loc.evaluate(\"\"\"\n",
    "      (el) => {\n",
    "        function findRowRoot(node){\n",
    "          while (node && node !== document.body) {\n",
    "            if (node.tagName === 'TR') return node;\n",
    "            const role = node.getAttribute && node.getAttribute('role');\n",
    "            if (role && role.toLowerCase() === 'row') return node;\n",
    "            const cls = (node.className || '').toString();\n",
    "            if (/\\\\brow\\\\b/i.test(cls)) return node;\n",
    "            node = node.parentElement;\n",
    "          }\n",
    "          return null;\n",
    "        }\n",
    "        const row = findRowRoot(el) || el.parentElement;\n",
    "        if (!row) return [];\n",
    "\n",
    "        // Prefer direct siblings after the label cell; otherwise, collect all leaf cells\n",
    "        const out = [];\n",
    "        const children = Array.from(row.children);\n",
    "        let startIdx = children.findIndex(ch => ch.contains(el));\n",
    "        if (startIdx >= 0) {\n",
    "          for (let i = startIdx + 1; i < children.length; i++) {\n",
    "            const c = children[i];\n",
    "            const t = (c.innerText || c.textContent || '').replace(/\\\\s+/g,' ').trim();\n",
    "            const aria = c.getAttribute && (c.getAttribute('aria-label') || '');\n",
    "            const data = c.getAttribute && (c.getAttribute('data-price') || '');\n",
    "            out.push([t, aria, data].filter(Boolean).join(' '));\n",
    "          }\n",
    "        }\n",
    "        if (out.length === 0) {\n",
    "          const cells = Array.from(row.querySelectorAll('td,th,a,button,div,span'));\n",
    "          for (const c of cells) {\n",
    "            if (c.contains(el) || el.contains(c)) continue;\n",
    "            const t = (c.innerText || c.textContent || '').replace(/\\\\s+/g,' ').trim();\n",
    "            const aria = c.getAttribute && (c.getAttribute('aria-label') || '');\n",
    "            const data = c.getAttribute && (c.getAttribute('data-price') || '');\n",
    "            out.push([t, aria, data].filter(Boolean).join(' '));\n",
    "          }\n",
    "        }\n",
    "        return out;\n",
    "      }\n",
    "    \"\"\")\n",
    "\n",
    "    # Parse decimals; require a decimal point to avoid '1' from '1 week'\n",
    "    vals = []\n",
    "    for txt in cell_texts:\n",
    "        m = DECIMAL_FALLBACK_RE.search(txt)\n",
    "        vals.append(float(m.group(1)) if m else None)\n",
    "        if len(vals) >= ncols:\n",
    "            break\n",
    "\n",
    "    if not any(v is not None for v in vals):\n",
    "        return None\n",
    "\n",
    "    # pad to ncols\n",
    "    return vals + [None] * (ncols - len(vals))\n",
    "\n",
    "# ---------- MODIFIED: parser that prefers $ text, then DOM fallback ----------\n",
    "async def _parse_grid_from_table(table_locator):\n",
    "    \"\"\"\n",
    "    Minimal-change parser:\n",
    "    - Force columns to the full set [8,16,32,64,128,256]\n",
    "    - For each duration label, grab that *row* from the DOM and parse the next cells left-to-right.\n",
    "    - Prefer $-anchored numbers; if missing (e.g., CSS-injected $ in 1-week links), fall back to decimals.\n",
    "    \"\"\"\n",
    "    counts_int = [8, 16, 32, 64, 128, 256]\n",
    "\n",
    "    rows = {}\n",
    "    for dur in DURATIONS_EXPECTED:\n",
    "        # Locate the row that contains exactly this duration label\n",
    "        row = table_locator.locator(\"tr\", has_text=re.compile(rf\"^\\s*{re.escape(dur)}\\s*$\", re.I)).first\n",
    "        if await row.count() == 0:\n",
    "            # Sometimes it's not a semantic <tr>; look for any row-like container\n",
    "            row = table_locator.locator(\"*[role='row'], div, section\").filter(\n",
    "                has_text=re.compile(rf\"^\\s*{re.escape(dur)}\\s*$\", re.I)\n",
    "            ).first\n",
    "\n",
    "        # Pull texts from the next N cells after the label cell\n",
    "        # We read both plain cell text and any nested link/button text/attributes.\n",
    "        cell_texts = await row.evaluate(\"\"\"\n",
    "          (el) => {\n",
    "            // Find the element that has the duration text, then read its siblings\n",
    "            const textMatches = (node, dur) =>\n",
    "              (node.innerText || node.textContent || '').trim().toLowerCase() === dur.toLowerCase();\n",
    "\n",
    "            function findLabelCell(root, dur){\n",
    "              const all = Array.from(root.querySelectorAll('th,td,div,span'));\n",
    "              return all.find(n => textMatches(n, dur)) || root;\n",
    "            }\n",
    "\n",
    "            function collectCellStrings(nodes){\n",
    "              const out = [];\n",
    "              for(const n of nodes){\n",
    "                const base = (n.innerText || n.textContent || '').replace(/\\\\s+/g,' ').trim();\n",
    "                const aria = n.getAttribute?.('aria-label') || '';\n",
    "                const title = n.getAttribute?.('title') || '';\n",
    "                const data  = n.getAttribute?.('data-price') || '';\n",
    "                // Include nested anchors/buttons in case the number lives there\n",
    "                const nested = Array.from(n.querySelectorAll('a,button,span,div')).map(x =>\n",
    "                  (x.innerText || x.textContent || '').replace(/\\\\s+/g,' ').trim()\n",
    "                ).filter(Boolean).join(' ');\n",
    "                out.push([base, aria, title, data, nested].filter(Boolean).join(' '));\n",
    "              }\n",
    "              return out;\n",
    "            }\n",
    "\n",
    "            const label = findLabelCell(el, /* dur injected below by Playwright */ '');\n",
    "            // Children after label within the same row/container\n",
    "            const siblings = Array.from(label.parentElement?.children || []);\n",
    "            const idx = siblings.indexOf(label);\n",
    "            const after = idx >= 0 ? siblings.slice(idx + 1) : [];\n",
    "\n",
    "            // If that yields nothing (non-tabular markup), fall back to all cells under row\n",
    "            const cells = after.length ? after : Array.from(el.querySelectorAll('td,th,div,span'));\n",
    "            return collectCellStrings(cells);\n",
    "          }\n",
    "        \"\"\", arg=dur)\n",
    "\n",
    "        # Now extract numbers from those cell strings\n",
    "        vals = []\n",
    "        for txt in cell_texts:\n",
    "            # 1) Try $-anchored prices first\n",
    "            m = PRICE_RE.search(txt)\n",
    "            if m:\n",
    "                vals.append(float(m.group(1)))\n",
    "            else:\n",
    "                # 2) Fallback to decimals (handles the 1-week link cells)\n",
    "                m2 = DECIMAL_FALLBACK_RE.search(txt)\n",
    "                vals.append(float(m2.group(1)) if m2 else None)\n",
    "            if len(vals) >= len(counts_int):\n",
    "                break\n",
    "\n",
    "        # Pad/trim to the expected 6 columns\n",
    "        vals = (vals + [None] * len(counts_int))[:len(counts_int)]\n",
    "        rows[dur] = vals\n",
    "\n",
    "    return counts_int, rows\n",
    "\n",
    "\n",
    "async def scrape_sfcompute_grid(headless=True, slow_mo=0):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=headless, slow_mo=slow_mo)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://sfcompute.com/buy\", wait_until=\"networkidle\")\n",
    "        await _select_explore_prices_tab(page)\n",
    "\n",
    "        all_rows = []\n",
    "        ts = dt.datetime.utcnow().isoformat(timespec=\"seconds\")\n",
    "\n",
    "        for gpu in GPU_TYPES:\n",
    "            await _select_gpu(page, gpu)\n",
    "            table = await _wait_table_update(page, gpu)\n",
    "            counts_int, rows = await _parse_grid_from_table(table)\n",
    "\n",
    "            for dur, vals in rows.items():\n",
    "                for c, val in zip(counts_int, vals):\n",
    "                    all_rows.append({\n",
    "                        \"ts_utc\": ts,\n",
    "                        \"gpu_type\": gpu,\n",
    "                        \"gpu_count\": c,\n",
    "                        \"duration\": dur,\n",
    "                        \"usd_per_gpu_hr\": val\n",
    "                    })\n",
    "\n",
    "        await browser.close()\n",
    "        return pd.DataFrame(all_rows)\n",
    "\n",
    "# ---- Run & Save ----\n",
    "df = await scrape_sfcompute_grid(headless=True)\n",
    "print(df)\n",
    "\n",
    "out_dir = Path(\"sfcompute_grid\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "today = dt.datetime.utcnow().strftime(\"%Y%m%d\")\n",
    "daily_file = out_dir / f\"grid_{today}.csv\"\n",
    "hist_file  = out_dir / \"grid_history.csv\"\n",
    "\n",
    "df.to_csv(daily_file, index=False)\n",
    "if hist_file.exists():\n",
    "    hist = pd.read_csv(hist_file)\n",
    "    hist = pd.concat([hist, df], ignore_index=True).drop_duplicates()\n",
    "    hist.to_csv(hist_file, index=False)\n",
    "else:\n",
    "    df.to_csv(hist_file, index=False)\n",
    "\n",
    "print(\"Saved:\", daily_file)\n",
    "print(\"History file updated:\", hist_file)\n",
    "#CORRECT "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
